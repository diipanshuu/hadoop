services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    hostname: namenode
    ports:
      - "9870:9870"  # NameNode Web UI
      - "8020:8020"  # NameNode RPC
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - CORE_CONF_hadoop_proxyuser_hue_hosts=*
      - CORE_CONF_hadoop_proxyuser_hue_groups=*
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_namenode_name_dir=/hadoop/dfs/name
      - HDFS_CONF_dfs_replication=2
    volumes:
      - namenode-data:/hadoop/dfs/name
    networks:
      - hadoop-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode1
    hostname: datanode1
    ports:
      - "9864:9864"  # DataNode Web UI
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_datanode_data_dir=/hadoop/dfs/data
      - HDFS_CONF_dfs_datanode_http_address=0.0.0.0:9864
      - HDFS_CONF_dfs_replication=2
    volumes:
      - datanode1-data:/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9864/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode2
    hostname: datanode2
    ports:
      - "9865:9864"  # DataNode Web UI (different host port)
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_datanode_data_dir=/hadoop/dfs/data
      - HDFS_CONF_dfs_datanode_http_address=0.0.0.0:9864
      - HDFS_CONF_dfs_replication=2
    volumes:
      - datanode2-data:/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9864/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-resourcemanager
    hostname: resourcemanager
    ports:
      - "8088:8088"  # ResourceManager Web UI
      - "8032:8032"  # ResourceManager RPC
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_resourcemanager_bind_host=0.0.0.0
      - YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
      - YARN_CONF_yarn_resourcemanager_resource_tracker_address=resourcemanager:8031
      - YARN_CONF_yarn_resourcemanager_admin_address=resourcemanager:8033
      - YARN_CONF_yarn_resourcemanager_webapp_address=resourcemanager:8088
      - YARN_CONF_yarn_timeline_service_enabled=false
      - YARN_CONF_yarn_nodemanager_resource_memory_mb=4096
      - YARN_CONF_yarn_scheduler_maximum_allocation_mb=4096
      - YARN_CONF_yarn_nodemanager_vmem_check_enabled=false
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-nodemanager1
    hostname: nodemanager1
    ports:
      - "8042:8042"  # NodeManager Web UI
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
      - YARN_CONF_yarn_resourcemanager_resource_tracker_address=resourcemanager:8031
      - YARN_CONF_yarn_nodemanager_aux_services=mapreduce_shuffle
      - YARN_CONF_yarn_nodemanager_aux_services_mapreduce_shuffle_class=org.apache.hadoop.mapred.ShuffleHandler
      - YARN_CONF_yarn_nodemanager_bind_host=0.0.0.0
      - YARN_CONF_yarn_nodemanager_hostname=nodemanager1
      - YARN_CONF_yarn_nodemanager_webapp_address=nodemanager1:8042
      - YARN_CONF_yarn_nodemanager_resource_memory_mb=4096
      - YARN_CONF_yarn_nodemanager_resource_cpu_vcores=4
      - YARN_CONF_yarn_nodemanager_vmem_check_enabled=false
      - YARN_CONF_yarn_nodemanager_disk_health_checker_enable=false
    networks:
      - hadoop-network
    depends_on:
      resourcemanager:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8042/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-historyserver
    hostname: historyserver
    ports:
      - "19888:19888"  # History Server Web UI
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - MAPRED_CONF_mapreduce_framework_name=yarn
      - MAPRED_CONF_mapreduce_jobhistory_address=historyserver:10020
      - MAPRED_CONF_mapreduce_jobhistory_webapp_address=historyserver:19888
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy

  hue:
    image: gethue/hue:latest
    container_name: hadoop-hue
    hostname: hue
    ports:
      - "8888:8888"  # Hue Web UI
    environment:
      - HUE_CONF_desktop_secret_key=hue_secret_key_change_me
      - HUE_CONF_desktop_http_host=0.0.0.0
      - HUE_CONF_desktop_http_port=8888
      - HUE_CONF_desktop_time_zone=UTC
      - HUE_CONF_hadoop_hdfs_clusters_default_fs_defaultfs=hdfs://namenode:8020
      - HUE_CONF_hadoop_hdfs_clusters_default_webhdfs_url=http://namenode:9870/webhdfs/v1
      - HUE_CONF_hadoop_yarn_clusters_default_resourcemanager_api_url=http://resourcemanager:8088
      - HUE_CONF_hadoop_yarn_clusters_default_history_server_api_url=http://historyserver:19888
    volumes:
      - hue-data:/usr/share/hue/data
    networks:
      - hadoop-network
    depends_on:
      - namenode
      - resourcemanager
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8888/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  namenode-data:
    name: hadoop-namenode-data
  datanode1-data:
    name: hadoop-datanode1-data
  datanode2-data:
    name: hadoop-datanode2-data
  hue-data:
    name: hadoop-hue-data

networks:
  hadoop-network:
    name: hadoop-network
    driver: bridge