services:
  namenode:
    image: apache/hadoop:3.3.6
    container_name: hadoop-namenode
    hostname: namenode
    ports:
      - "9870:9870"  # NameNode Web UI
      - "8020:8020"  # NameNode RPC
    environment:
      CLUSTER_NAME: hadoop-cluster
    env_file:
      - ./hadoop.env
    volumes:
      - namenode-data:/hadoop/dfs/name
    networks:
      - hadoop-network
    command: ["hdfs", "namenode"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode1:
    image: apache/hadoop:3.3.6
    container_name: hadoop-datanode1
    hostname: datanode1
    ports:
      - "9864:9864"  # DataNode Web UI
    env_file:
      - ./hadoop.env
    volumes:
      - datanode1-data:/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    command: ["hdfs", "datanode"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9864/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode2:
    image: apache/hadoop:3.3.6
    container_name: hadoop-datanode2
    hostname: datanode2
    ports:
      - "9865:9864"  # DataNode Web UI (different host port)
    env_file:
      - ./hadoop.env
    volumes:
      - datanode2-data:/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    command: ["hdfs", "datanode"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9864/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  resourcemanager:
    image: apache/hadoop:3.3.6
    container_name: hadoop-resourcemanager
    hostname: resourcemanager
    ports:
      - "8088:8088"  # ResourceManager Web UI
      - "8032:8032"  # ResourceManager RPC
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    command: ["yarn", "resourcemanager"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  nodemanager1:
    image: apache/hadoop:3.3.6
    container_name: hadoop-nodemanager1
    hostname: nodemanager1
    ports:
      - "8042:8042"  # NodeManager Web UI
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-network
    depends_on:
      resourcemanager:
        condition: service_healthy
    command: ["yarn", "nodemanager"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8042/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  historyserver:
    image: apache/hadoop:3.3.6
    container_name: hadoop-historyserver
    hostname: historyserver
    ports:
      - "19888:19888"  # History Server Web UI
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    command: ["mapred", "historyserver"]

  hue:
    image: gethue/hue:latest
    container_name: hadoop-hue
    hostname: hue
    ports:
      - "8888:8888"  # Hue Web UI
    environment:
      - HUE_CONF_desktop_secret_key=hue_secret_key_change_me
      - HUE_CONF_desktop_http_host=0.0.0.0
      - HUE_CONF_desktop_http_port=8888
      - HUE_CONF_desktop_time_zone=UTC
      - HUE_CONF_hadoop_hdfs_clusters_default_fs_defaultfs=hdfs://namenode:8020
      - HUE_CONF_hadoop_hdfs_clusters_default_webhdfs_url=http://namenode:9870/webhdfs/v1
      - HUE_CONF_hadoop_yarn_clusters_default_resourcemanager_api_url=http://resourcemanager:8088
      - HUE_CONF_hadoop_yarn_clusters_default_history_server_api_url=http://historyserver:19888
    volumes:
      - ./hue-config:/usr/share/hue/desktop/conf
      - hue-data:/usr/share/hue/data
    networks:
      - hadoop-network
    depends_on:
      - namenode
      - resourcemanager
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8888/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  namenode-data:
    name: hadoop-namenode-data
  datanode1-data:
    name: hadoop-datanode1-data
  datanode2-data:
    name: hadoop-datanode2-data
  hue-data:
    name: hadoop-hue-data

networks:
  hadoop-network:
    name: hadoop-network
    driver: bridge